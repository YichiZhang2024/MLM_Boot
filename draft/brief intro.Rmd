Data in social and behavioral science research commonly have a multilevel structure, where units are nested within clusters. For example, students are nested within classrooms in educational studies; participants are repeatedly measured at different time points in longitudinal studies. Multilevel modeling (MLM), also known as hierarchical linear models and mixed effects models, has been widely used to account for clustered data. The most common estimation method for MLM is the class of methods that are based on maximum likelihood (ML) estimation, which generates the most probable value of model parameters given the observed data [@raudenbush2002]. 
<!-- ML: Not clear whether you meant ML to be an estimation method, or a class of estimation methods that include REML as well -->
<!-- ML: Does the literature use FIML? It seems more common in the missing data literature -->
<!-- Some common versions of ML are restricted maximum likelihood (REML) and full information maximum likelihood (FIML). -->
The accuracy of the ML estimates and the associated statistical inferences depend on whether the underlying assumptions are satisfied. Specifically, ML assumes that the data have a sufficiently large sample size and residuals at each level follow independent and identical distributions [i.i.d.\; @vanderleeden2008]. When these two assumptions are violated, the desirable properties of ML, namely consistency, asymptotic efficiency, and asymptotic normality, may not hold, resulting in biased standard error estimates with inaccurate inferences. The bootstrap, a resampling method that approximates the sampling distribution of statistics, can be used to obtain more accurate standard error estimates, confidence intervals, and statistical inferences when assumptions are violated [@busing1993]. <!-- ML: how about inferences and confidence intervals? -->

In this chapter, we explain different types of bootstrapping procedures for MLM and illustrate how and when to use these bootstrap methods in applied research. Section I is an overview of assumption violations in MLM, followed by the general idea of bootstrap methods for regression models. In Section II, we discuss the challenges of bootstrapping in MLM and introduce several bootstrapping procedures. Section III is a discussion of bootstrap confidence intervals and comparisons of some commonly available options. Section IV demonstrates the use of various bootstrapping procedures on an empirical example discussed in @snijders2012, which investigates whether school differences exist in studentsâ€™ language proficiency. The last section provides suggestions on available software and resources for MLM bootstrap methods. 