
```{r echo=FALSE}
# helper functions
# comma <- function(x) format(x, digits = 2, big.mark = ",")
comma <- function(x) {
  if (is.null(x)) NULL
  else format(round(x, digits = 2), big.mark = ",")
}
get_ci <- function(boo_ci, type) {
  paste0("(", paste(comma(tail(boo_ci[[type]][1, ], 2L)), collapse = ", "), ")")
}
get_ci_tab <- function(boo_ci_lst, type) {
  npar <- length(boo_ci_lst[[1]])
  unlist(lapply(boo_ci_lst, function(x) {
    unlist(lapply(x, function(y) { get_ci(y, type) }))
  })) %>%
    matrix(ncol = npar, byrow = TRUE)
}

# load boot results
boo_par_fr <- readRDS("illustration_boo_res/boo_par_fr.rds")
boo_par_icc <- readRDS("illustration_boo_res/boo_par_icc.rds")

boo_res_fr <- readRDS("illustration_boo_res/boo_res_fr.rds")
boo_cgr_fr <- readRDS("illustration_boo_res/boo_cgr_fr.rds")
boo_res_icc <- readRDS("illustration_boo_res/boo_res_icc.rds")
boo_cgr_icc <- readRDS("illustration_boo_res/boo_cgr_icc.rds")

inf_val_fr <- readRDS("illustration_boo_res/inf_val_fr.rds")
inf_val_icc <- readRDS("illustration_boo_res/inf_val_icc.rds")

boo_cas_fr <- readRDS("illustration_boo_res/boo_cas_fr.rds")
boo_cas1_fr <- readRDS("illustration_boo_res/boo_cas1_fr.rds")
boo_cas_icc <- readRDS("illustration_boo_res/boo_cas_icc.rds")
boo_cas1_icc <- readRDS("illustration_boo_res/boo_cas1_icc.rds")

boo_wil_fr <- readRDS("illustration_boo_res/boo_wil_fr.rds")
boo_wil_icc <- readRDS("illustration_boo_res/boo_wil_icc.rds")
```

In this section, we illustrate three bootstrap approaches (i.e., parametric, residual, and case) with the *bootmlm* R package and wild bootstrap with the *lmeresampler* R package on an empirical example. In particular, we will obtain confidence intervals for the fixed effects, intraclass correlations (ICC), and the variance explained by the fixed effects ($R^2$). 

The empirical example is an  elementary school study by [@knuver1989; @knuver1993; @doolaard1999], whose data shared and used in @snijjders2012. This study contains data for 3758 students, after a list-wise deletion of 258 students, from 211 schools with class sizes ranging between 5 and 36. As shown in @snijders2012 (Chapter 8 and 10), the variables in the data appear to violate the assumptions of homoscesdaticity, and the intelligence variable appears to also violate the assumption of normality. 

Following the analyses in @snijders2012 (Chapter 8), we use a two-level model, with students nested within schools, to predict language test scores ($\text{lang}_{ij}$) with students' intelligence ($\text{IQ}_{ij}$), gender ($\text{gender}_{ij}$), and family's socio-economic status ($\text{SES}_{ij}$). The model equation is
\begin{align}
\begin{split}
\text{Level 1: } & \text{lang}_{ij} = \beta_{0j} + \beta_{1j}\text{IQ}_{ij} + \beta_{2j}\text{SES}_{ij} + \beta_{3j} \text{gender}_{ij} + \beta_{4j} \text{IQ}_{ij} \times \text{SES}_{ij} + e_{ij}, \quad e_{ij} \sim N(0, \sigma^2)\\
\text{Level 2: } & \beta_{0j} = \gamma_{00} + \gamma_{01} \text{school\_IQ}_{j} + \gamma_{02} \text{school\_SES}_{j} + \gamma_{03}\text{school\_IQ}\times\text{school\_SES} + u_{0j} \\
& \beta_{1j} = \gamma_{10} + u_{1j}\\
& \beta_{2j} = \gamma_{20} \\ 
& \beta_{3j} = \gamma_{30} \\ 
& \beta_{4j} = \gamma_{40} \\
& \begin{pmatrix}
u_{0j} \\ u_{1j}
\end{pmatrix}\sim N\left(
\begin{bmatrix}0 \\ 
0 \end{bmatrix}, 
\begin{bmatrix}\tau^2_{0}\\
\tau_{01} & \tau^2_{1}
\end{bmatrix}\right) \\
\text{Combined: } & \text{lang}_{ij} = \gamma_{00} + \gamma_{10}\text{IQ}_{ij} + \gamma_{20}\text{SES}_{ij} + \gamma_{30}\text{gender}_{ij} + \gamma_{40}\text{IQ}_{ij} \times \text{SES}_{ij}\text{gender}_{ij} + \\
& \quad \gamma_{01} \text{school\_IQ}_{j} + \gamma_{02} \text{school\_SES}_j + \gamma_{03} \text{school\_SES}_j \times \text{school\_IQ}_j + \\
& \quad u_{0j} + u_{1j} \text{IQ}_{ij} + e_{ij}, 
(\#eq:sj-mod)
\end{split}
\end{align}
where $\text{IQ}_j$ and $\text{school\_SES}_j$ are the average intelligence and SES of students within each school, respectively; $\gamma_{00}$ is the grand intercept of language scores; $\gamma_{01}$ and $\gamma_{02}$ are the school-level fixed effects of intelligence and SES, respectively; $\gamma_{03}$ is the school-level interaction between intelligence and SES; $\gamma_{10}$ and $\gamma_{20}$ are the student-level fixed effects of intelligence and SES, respectively; $\gamma_{30}$ is the student-level interaction between intelligence and SES; $u_{0j}$ is the random effect from the grand intercept; and $u_{1j}$ is the random effect from the student-level intelligence. For reproducibility, we use the following syntax to download and import the dataset from the website of @snijders2012 to our local R environment. 

\singlespacing

```{r}
temp <- tempfile()
download.file("https://www.stats.ox.ac.uk/~snijders/mlbook2_r_dat.zip", temp)
sj_dat <- read.table(unz(temp, "mlbook2_r.dat"), header = TRUE)
```

\doublespacing

The `bootmlm` R package is available on github and can be installed using the *remotes* package. 

\singlespacing

```{r eval=FALSE}
# install.packages("remotes")
remotes::install_github("marklhc/bootmlm")
```

\doublespacing

We begin by loading the required R packages, including *lme4*, which performs multilevel analysis, *boot*, which computes confidence intervals for bootstrap samples, and *MuMIn*, which computes $R^2$. If some of the packages have not been installed locally, we can install them from CRAN using the command `install.packages()`. 

\singlespacing

```{r message=FALSE}
library(lme4)
library(bootmlm)
library(lmeresampler)
library(boot)
library(MuMIn)
```


\doublespacing

In the following, we perform two models in *lme4*: (a) the null model (the unconditional model) that has no predictors, given by
\begin{align}
\text{lang}_{ij} & = \gamma_{00} + u_{0j} + e_{ij} \\
u_{0j} \sim N(0, \tau^2_{00}), \quad e_{ij} \sim N(0, \sigma^2), 
\end{align}
and (b) the final model in @snijders2012, as shown in Model\ \@ref(eq:sj-mod). We will compute ICC, defined as $\frac{\tau^2_{00}}{\tau^2_{00} + \sigma^2}$, based on the null model and obtain the fixed effects and variance explained by the fixed effects based on the final model. 

\singlespacing

```{r}
# unconditional model
mod_0 <- lmer(langPOST ~ (1 | schoolnr), data = sj_dat)
# final model
mod_f <- lmer(langPOST ~ IQ_verb*ses + sex + sch_iqv*sch_ses + (IQ_verb | schoolnr), 
              data = sj_dat)
```

\doublespacing

We first define two functions, `fixef_rsq()` which takes the final model to compute the fixed effects and $R^2$, and `icc()` which takes the null model to compute ICC. These functions will be used to perform bootstrapping, which requires intensive computation, and thus we use the operator `@` to more efficiently extract the parameter coefficients from an `lme4` model object. 


\singlespacing

```{r}
# function for obtaining fixed effects and R^2
fixef_rsq <- function(mod) {
  fixef <- mod@beta
  rsq <- MuMIn::r.squaredGLMM(mod)[1]
  c(fixef = fixef, rsq = rsq)
}
# function for obtaining intraclass correlation
icc <- function(mod) {
  1 / (1 + mod@theta^(-2))
}
```

\doublespacing

`fixef_rsq()` yields estimates for nine parameters, including the eight fixed effects ($\gamma_{00}, \gamma_{01}, \gamma_{02}, \gamma_{03}, \gamma_{10}, \gamma_{20}, \gamma_{30}, \gamma_{40}$), and `icc()` computes the estimate for ICC. Executing `fixef_rsq(mod_f)` and `icc(mod_0)` gives us the following parameter estimates from the two models. 

\singlespacing

```{r echo=FALSE, warning=FALSE}
out <- c(fixef_rsq(mod_f), icc(mod_0))
names(out) <- c(names(fixef(mod_f)), "Rsq", "ICC")
out
```

\doublespacing

<!-- ## Assumption Checking -->


## Parametric Bootstrap

At the moment of writing, the `bootstrap_mer()` function in *bootmlm* supports three main types of bootstrapping---parametric, residual, and case. To perform parametric bootstrap, we denote `type = "parametric"` in the function and specify the fitted model object from *lmer* (i.e., `mod_f` and `mod_0`) along with the defined function for obtaining the parameter estimates (i.e., `fixef_rsq()` and `icc()`). `nsim` refers to the number of bootstrap samples ($R$), which is generally recommended to be large for stable estimates. In this illustration, we use $R = 1,999$. 

\singlespacing

```{r eval=FALSE}
boo_par_fr <- bootstrap_mer(mod_f, fixef_rsq, nsim = 1999L, type = "parametric")
boo_par_icc <- bootstrap_mer(mod_0, icc, nsim = 1999L, type = "parametric")
```

\doublespacing

We can use the `boot.ci()` function in *boot* to compute the confidence intervals for the bootstrap samples. For parametric bootstrap, this function provides three ways to construct confidence intervals: normal, basic and percentile. As `boo_par_fr` contains bootstrap samples for nine parameters, `lapply()` allows us to compute confidence intervals for all of them simultaneously. 

\singlespacing

```{r}
boo_par_fr_ci <- lapply(1:9, function(i) {
  boot.ci(boo_par_fr, type = c("norm", "basic", "perc"), index = i)
})
boo_par_icc_ci <- boot.ci(boo_par_icc, type = c("norm", "basic", "perc"), 
                          index = 1L)
```

\doublespacing

## Residual Bootstrap

`bootmlm` implements three methods for residual bootstrap: (a) differentailly reflated residual bootstrap, (b) Carpenter-Goldstein-Rashbash's residual bootstrap [CGR; @carpenter2003], and (c) transformational residual bootstrap by @leeden2008. The residuals (denoted as $\tilde u$ and $\tilde e$), generally empirical Bayes estimates, are shrinkage parameters and have sampling variabilities much smaller than the population random effects, $u$ and $e$. These methods for residual bootstrap accounts for the small sampling variabilities by rescaling $\tilde u$ and $\tilde e$. The transformational residual bootstrap is particular useful for bounded parameters, such as ICC and $R^2$. Here we demonstrate the first two methods and discuss the transformational residual bootstrap in a separate subsection. 

The first residual bootstrap method rescales $\tilde u$ and $\tilde e$ to match their sampling variabilities with those of $u$ and $e$. The second method, CGR, rescales the sample covariance matrix of the realized values of the residuals to match the model-implied variance components. To perform the two residual bootstrap methods, specify `type = "residual"` and `type = "residual_cgr"`, respectively, in `bootmlm::bootstrap_mer`. 

\singlespacing

```{r eval=FALSE}
# Reflated residual
boo_res_fr <- bootstrap_mer(mod_f, fixef_rsq, nsim = 1999L, type = "residual")
boo_res_icc <- bootstrap_mer(mod_0, icc, nsim = 1999L, type = "residual")
# CGR
boo_cgr_fr <- bootstrap_mer(mod_f, fixef_rsq, nsim = 1999L, type = "residual_cgr")
boo_cgr_icc <- bootstrap_mer(mod_0, icc, nsim = 1999L, type = "residual_cgr")
```

\doublespacing

There are four ways to construct confidence intervals with `boot::boot.ci()` with residual bootstrap methods, including the three ways mentioned earlier and additionally the bias-corrected and accelerated bootstrap (BCa). As discussed in Section III, the influence values are needed to compute confidence intervals with BCa and can be obtained using the function `empinf_mer()` in *botmlm*. This function requires the inputs of the fitted model (`mod_f` and `mod_0`), the defined function that compute the parameter estimate(s) (`fixef_rsq()` and `icc()`), and the index of the statistic in the output of the defined function. As `fixef_rsq()` yields nine statistics, we can use `lapply()` to conveniently compute the influence values for all of them at once. 

\singlespacing

```{r eval=FALSE}
inf_val_fr <- lapply(1:9, function(i) {
  empinf_mer(mod_f, fixef_rsq, index = i)
})
inf_val_icc <- empinf_mer(mod_0, icc, index = 1)
```

We additionally specify `"bca"` in `type` to compute the confidence interval with BCa. 

```{r}
# Residual bootstrap
boo_res_fr_ci <- lapply(1:9, function(i) {
  boot::boot.ci(boo_res_fr, type = c("norm", "basic", "perc", "bca"), 
                index = i, L = inf_val_fr[[i]])
})
boo_res_icc_ci <- boot::boot.ci(boo_res_icc, type = c("norm", "basic", "perc", "bca"), 
                                index = 1L, L = inf_val_icc)
# CGR
boo_cgr_fr_ci <- lapply(1:9, function(i) {
  boot::boot.ci(boo_cgr_fr, type = c("norm", "basic", "perc", "bca"), 
                index = i, L = inf_val_fr[[i]])
})
boo_cgr_icc_ci <- boot::boot.ci(boo_cgr_icc, type = c("norm", "basic", "perc", "bca"), 
                                index = 1L, L = inf_val_icc)
```

\doublespacing

## Case Bootstrap

With case bootstrap in multilevel modeling, clusters are sampled with replacement using and the argument of `type = "case"` in `bootmlm::bootstrap_mer()`. Optionally, we can further resample the cases (observations) within each cluster, which can be done using the `lv1_resample = TRUE` arguement. Unlike the other bootstrap methods, *bootmlm* currently only supports the case bootstrap for two-level models. 

```{r eval=FALSE}
# Fixed effects and Rsq
boo_cas_fr <- bootstrap_mer(mod_f, fixef_rsq, nsim = 1999L, type = "case")
boo_cas1_fr <- bootstrap_mer(mod_f, fixef_rsq, nsim = 1999L, type = "case", 
                             lv1_resample = TRUE)
# ICC
boo_cas_icc <- bootstrap_mer(mod_0, icc, nsim = 1999L, type = "case")
boo_cas1_icc <- bootstrap_mer(mod_0, icc, nsim = 1999L, type = "case", 
                              lv1_resample = TRUE)
```

`boot::boot.ci()` also supports four ways to compute confidence interval, including normal, basic, percentile, and BCa. Again, the influence values are needed to compute confidence intervals with BCa, and we use the `lapply()` function to compute the confidence intervals for all nine statistics defined in `fixef_rsq()` in one go.  

```{r}
# Only sampling clusters
boo_cas_fr_ci <- lapply(1:9, function(i) {
  boot::boot.ci(boo_cas_fr, type = c("norm", "basic", "perc", "bca"), 
                index = i, L = inf_val_fr[[i]])
})
boo_cas_icc_ci <- boot::boot.ci(boo_cas_icc, type = c("norm", "basic", "perc", "bca"), 
                                index = 1L, L = inf_val_icc)
# Transformational (with correction)
boo_cas1_fr_ci <- lapply(1:9, function(i) {
  boot::boot.ci(boo_cas1_fr, type = c("norm", "basic", "perc", "bca"), 
                index = i, L = inf_val_fr)
})
boo_cas1_icc_ci <- boot::boot.ci(boo_cas1_icc, type = c("norm", "basic", "perc", "bca"), 
                                 index = 1L, L = inf_val_icc)
```


## Wild Bootstrap

While wild bootstrap is unavailable in *bootmlm*, we can use the function `wild_bootstrap()` in the *lmeresampler* R package. Similar to those in `bootstrap_mer()`, the required input arguments in `wild_bootstrap()` are the fitted model object, the defined function that computes the parameter estimates (`.f`), and the number of bootstrap samples (`B`). 

```{r eval=FALSE}
boo_wil_fr <- wild_bootstrap(mod_f, .f = fixef_rsq, B = 1999L)
boo_wil_icc <- wild_bootstrap(mod_0, .f = icc, B = 1999L)
```

Similarly, there are four ways to construct the confidence intervals with wild bootstrap, which can be obtained using the `confint()` function from the *stats* package. 

```{r}
boo_wil_fr_ci <- confint(boo_wil_fr, method = c("norm", "basic", "perc", "bca"))
boo_wil_icc_ci <- confint(boo_wil_icc, method = c("norm", "basic", "perc", "bca"))
```


## Comparison

Tables\ \@ref(tab:comp1) and\ \@ref(tab:comp2) summarize the standard errors and confidence intervals for all parameters with the illustrated bootstrap approaches. Recall that parametric bootstrap assumes normality; residual bootstrap relaxes the normality assumption but still relies on the homoscedasticity assumption; cases bootstrap relaxes both assumptions but requires more time to perform with lower computational efficiency. Since most variables in the data violate the homoscesdasticity assumption, and the intelligence variable further violates the normality assumption, we expect to see differences in the standard errors and confidence intervals between methods, particularly for the fixed effects related to intelligence. 

For the school-level fixed effects, the confidence intervals are similar across methods, except for the school-mean intelligence ($\gamma_{01}$). The standard errors are also similar across methods, except for the grand intercept ($\gamma_{00}$) and the school-mean intelligence. The cases bootstrap with resampling within clusters show the most drastic differences with larger standard errors and wider confidence intervals. For the student-level fixed effects, the standard errors and confidence intervals are similar across methods, except for the student-level intelligence ($\gamma_{10}$) and the interaction between the student-level intelligence and socio-economic status ($\gamma_{30}$). Similarly, the cases bootstrap with resampling within clusters give larger standard errors and wider confidence intervals. 

For ICC and $R^2$, all methods yield similar standard errors and confidence intervals are similar. Cases bootstrap with resampling within clusters tend to give a lower normal and basic confidence intervals than other confidence interval methods for ICC. 

```{r echo=FALSE}
boo_lst_fr <- list(boo_par_fr, boo_res_fr, boo_cgr_fr, 
                   boo_cas_fr, boo_cas1_fr)
boo_lst_icc <- list(boo_par_icc, boo_res_icc, boo_cgr_icc, 
                   boo_cas_icc, boo_cas1_icc)
boo_ci_lst <- list(append(boo_par_fr_ci, list(boo_par_icc_ci)), 
                   append(boo_res_fr_ci, list(boo_res_icc_ci)), 
                   append(boo_cgr_fr_ci, list(boo_cgr_icc_ci)), 
                   append(boo_cas_fr_ci, list(boo_cas_icc_ci)), 
                   append(boo_cas1_fr_ci, list(boo_cas1_icc_ci)))

sd_fr <- unlist(lapply(boo_lst_fr, function(x) {
  apply(x$t, 2, function(y) { comma(sd(y)) })
})) |> matrix(ncol = 9, byrow = TRUE)
sd_icc <- lapply(boo_lst_icc, function(x) { comma(sd(x$t)) }) |> unlist()

sd <- cbind(sd_fr, sd_icc)
normal <- get_ci_tab(boo_ci_lst, "normal")
basic <- get_ci_tab(boo_ci_lst, "basic")
percentile <- get_ci_tab(boo_ci_lst, "percent")
bca <- get_ci_tab(boo_ci_lst, "bca")
compare_tab <- data.frame(
  stat = rep(c("SE", "Normal", "Basic", "Percentile", "BCA"), each = 5), 
  boo_type = rep(c("Parametric", "Residual", "CGR", 
                   "Case", "Case (within cluster)"), 5), 
  rbind(sd, normal, basic, percentile, bca)
) %>%
  mutate_all(~ ifelse(. == "()", "--", .))
```


```{r comp1, echo=FALSE}
# V1 = (Intercept)/gamma00, V2 = IQ_verb/gamma10, V3 = ses/gamma20, 
# V4 = sex/gamma30, V5 = sch_iqv/gamma01, V6 = sch_ses/gamma02, 
# V7 = IQ_verb:ses/gamma40, V8 = sch_iqv:sch_ses/gamma03
compare_tab %>%
  select(stat:V1, V5:V6, V8, sd_icc) %>%
  knitr::kable(
    booktabs = TRUE, 
    escape = FALSE, 
    col.names = c("", "Bootstrap Type", "$\\gamma_{00}$", "$\\gamma_{01}$", 
                  "$\\gamma_{02}$", "$\\gamma_{03}$", "ICC")
  ) %>%
  collapse_rows(1:2) %>%
  add_header_above(c(" " = 2, "School-Level Fixed Effects" = 4, " " = 1), 
                   escape = FALSE) %>%
  kable_styling(font_size = 10.5)
```


```{r comp2, echo=FALSE}
compare_tab %>%
  select(stat:boo_type, V2:V4, V7, V9) %>%
  knitr::kable(
    booktabs = TRUE, 
    escape = FALSE, 
    col.names = c("", "Bootstrap Type", "$\\gamma_{10}$", 
                  "$\\gamma_{20}$", "$\\gamma_{30}$", "$\\gamma_{40}$", 
                  "$R^2$")
  ) %>%
  collapse_rows(1:2) %>%
  add_header_above(c(" " = 2, "Student-Level Fixed Effects" = 4, " " = 1),  
                   escape = FALSE) %>%
  kable_styling(font_size = 10.5)
```


## Bootstrap CI With Transformation

* Use R^2 as an example

* Cite the paper for ICC



